{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Varieties of Clustering ... and Penguins\n",
    "\n",
    "In what follows I want to illustrate how different clustering algorithms work. I'll be applying the techniques to the penguins dataset inside the `seaborn` library. First I'll import the tools I'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import AffinityPropagation,\\\n",
    "AgglomerativeClustering, Birch, DBSCAN, KMeans, MeanShift,\\\n",
    "OPTICS, SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.pyplot.style.use('fivethirtyeight')\n",
    "mpl.pyplot.set_cmap('Spectral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Since I want to use 2-dimensional graphs to illustrate `sklearn`'s clustering techniques, I want to choose features of the penguins data that serve to distinguish the species well one from another. There are three species in the dataset: Adelie, Chinstrap, and Gentoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "\n",
    "penguins = sns.load_dataset('penguins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are only 19 null values in the whole dataset, I'll just drop the offending rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_clean = penguins.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummying out Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_cat = pd.get_dummies(penguins_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for Predictive Features\n",
    "\n",
    "I've dummied out the species feature, so I'll check correlation values for each species with the remaining features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adel_corrs = abs(penguins_cat.corr()['species_Adelie']).sort_values(ascending=False)\n",
    "adel_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(penguins_cat.corr()['species_Adelie']['culmen_length_mm'])\n",
    "print(penguins_cat.corr()['species_Adelie']['flipper_length_mm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short culmens and short flippers are most highly correlated with belonging to the Adelie species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chin_corrs = abs(penguins_cat.corr()['species_Chinstrap']).sort_values(ascending=False)\n",
    "chin_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(penguins_cat.corr()['species_Chinstrap']['island_Dream'])\n",
    "print(penguins_cat.corr()['species_Chinstrap']['island_Biscoe'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being from Dream Island and *not* being from Biscoe Island are most highly correlated with belonging to the Chinstrap species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_corrs = abs(penguins_cat.corr()['species_Gentoo']).sort_values(ascending=False)\n",
    "gen_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(penguins_cat.corr()['species_Gentoo']['flipper_length_mm'])\n",
    "print(penguins_cat.corr()['species_Gentoo']['culmen_depth_mm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long flippers and shallow culmens are most highly correlated with belonging to the Gentoo species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing Final Features\n",
    "\n",
    "We looked at the top two most highly correlated features for each species and found five different features across the dataset. To make our choice of the two we'll use for plotting purposes, we'll take a weighted average of the (absolute values of the) correlations across the three species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the ratios of species representation in the dataset\n",
    "\n",
    "adel_rat = penguins_cat['species_Adelie'].sum() / penguins_cat.shape[0]\n",
    "chin_rat = penguins_cat['species_Chinstrap'].sum() / penguins_cat.shape[0]\n",
    "gen_rat = penguins_cat['species_Gentoo'].sum() / penguins_cat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the weighted average of correlations\n",
    "\n",
    "(adel_rat * adel_corrs + chin_rat * chin_corrs + gen_rat * gen_corrs)\\\n",
    "          .sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignoring the species features themselves, our top scorers are flipper length and culmen length, so we'll go with those.\n",
    "\n",
    "These are both numeric features, so we'll go back to our dataset without the dummies. In order to be able to pass the species into `matplotlib` plots' color parameter, we'll also use `sklearn`'s `LabelEncoder` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_species = LabelEncoder()\n",
    "pen_species.fit(penguins_clean['species'])\n",
    "\n",
    "penguins_num = penguins_clean.copy()\n",
    "penguins_num['spec_num'] = pen_species.transform(penguins_num['species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(figsize=(8, 6))\n",
    "\n",
    "scatter = ax.scatter(x=penguins_num['flipper_length_mm'],\n",
    "          y=penguins_num['culmen_length_mm'],\n",
    "          c=penguins_num['spec_num'])\n",
    "\n",
    "legend1 = ax.legend(*scatter.legend_elements(),\n",
    "                    loc=\"best\", title=\"Classes\")\n",
    "ax.add_artist(legend1)\n",
    "ax.set_title('Ground Truth: Penguin Species by Flipper and Culmen Lengths');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying our Species Identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pen_species.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Class 0 represents Adelie\n",
    "- Class 1 represents Chinstrap\n",
    "- Class 2 represents Gentoo\n",
    "\n",
    "If we calculate the means of Adelie flipper and culmen lengths, we should find the center of the reddish region above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(penguins_num[penguins_num['species'] == 'Adelie']['flipper_length_mm'].mean())\n",
    "print(penguins_num[penguins_num['species'] == 'Adelie']['culmen_length_mm'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we calculate the means of Chinstrap flipper and culmen lengths, we should find the center of the yellowish region above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(penguins_num[penguins_num['species'] == 'Chinstrap']['flipper_length_mm'].mean())\n",
    "print(penguins_num[penguins_num['species'] == 'Chinstrap']['culmen_length_mm'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we calculate the means of Gentoo flipper and culmen lengths, we should find the center of the bluish region above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(penguins_num[penguins_num['species'] == 'Gentoo']['flipper_length_mm'].mean())\n",
    "print(penguins_num[penguins_num['species'] == 'Gentoo']['culmen_length_mm'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Preparation\n",
    "\n",
    "The last thing we want to do is to drop the species column so that we can train our clustering algorithms without any information about the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_X = penguins_num.drop('species', axis=1)\\\n",
    "[['flipper_length_mm', 'culmen_length_mm']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "### Strategy 1: Affinity Propagation\n",
    "\n",
    "Affinity propagation is about finding exemplars for clusters. The goal is to find data points that serve well as exemplars based on their similarity (distance) to the other points. The `damping` parameter, as the name suggets, helps to prevent oscillations.\n",
    "\n",
    "The number of final clusters is not determined in advance. Observe the different predictions resulting from only slight changes in the starting datset below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = np.array([1, 2, 3, 4])[:, np.newaxis]\n",
    "var2 = np.array([1, 2, 4, 5])[:, np.newaxis]\n",
    "var3 = np.array([1, 3, 4, 5])[:, np.newaxis]\n",
    "var4 = np.array([1, 2, 3, 5])[:, np.newaxis]\n",
    "\n",
    "print(AffinityPropagation().fit_predict(var1))\n",
    "print(AffinityPropagation().fit_predict(var2))\n",
    "print(AffinityPropagation().fit_predict(var3))\n",
    "print(AffinityPropagation().fit_predict(var4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions are the clusters to which each point is predicted to belong. See `sklearn` documentation [here](https://scikit-learn.org/stable/modules/clustering.html#affinity-propagation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff = AffinityPropagation()\n",
    "# default settings first\n",
    "\n",
    "aff.fit(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = aff.predict(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "scatter = ax[0].scatter(x=penguins_num['flipper_length_mm'],\n",
    "          y=penguins_num['culmen_length_mm'],\n",
    "          c=penguins_num['spec_num'])\n",
    "\n",
    "legend1 = ax[0].legend(*scatter.legend_elements(),\n",
    "                    loc=\"best\", title=\"Classes\")\n",
    "ax[0].add_artist(legend1)\n",
    "ax[0].set_title('Ground Truth')\n",
    "\n",
    "ax[1].scatter(x=penguins_X['flipper_length_mm'],\n",
    "          y=penguins_X['culmen_length_mm'],\n",
    "          c=preds1)\n",
    "ax[1].set_title(f'Affinity Propagation, {len(np.unique(preds1))} Clusters');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjust `damping`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff2 = AffinityPropagation(damping=0.975)\n",
    "# We'll try setting the damping up toward the higher end\n",
    "\n",
    "aff2.fit(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1b = aff2.predict(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "scatter = ax[0].scatter(x=penguins_num['flipper_length_mm'],\n",
    "          y=penguins_num['culmen_length_mm'],\n",
    "          c=penguins_num['spec_num'])\n",
    "\n",
    "legend1 = ax[0].legend(*scatter.legend_elements(),\n",
    "                    loc=\"best\", title=\"Classes\")\n",
    "ax[0].add_artist(legend1)\n",
    "ax[0].set_title('Ground Truth')\n",
    "\n",
    "ax[1].scatter(x=penguins_X['flipper_length_mm'],\n",
    "          y=penguins_X['culmen_length_mm'],\n",
    "          c=preds1b)\n",
    "ax[1].set_title(f'Affinity Propagation, {len(np.unique(preds1b))} Clusters');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 2: Agglomerative Clustering\n",
    "\n",
    "Agglomerative clustering is a \"bottom-up\" mode of hierarchical clustering: Call each point its own cluster. Then find the two clusters that are most similar and merge those into a new cluster. Then find the next two closest clusters and merge them. Repeat until a desired number of clusters is reached. See `sklearn` documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = AgglomerativeClustering(n_clusters=3)\n",
    "# Setting to 3 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = agg.fit_predict(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "scatter = ax[0].scatter(x=penguins_num['flipper_length_mm'],\n",
    "          y=penguins_num['culmen_length_mm'],\n",
    "          c=penguins_num['spec_num'])\n",
    "\n",
    "legend1 = ax[0].legend(*scatter.legend_elements(),\n",
    "                    loc=\"best\", title=\"Classes\")\n",
    "ax[0].add_artist(legend1)\n",
    "ax[0].set_title('Ground Truth')\n",
    "\n",
    "def switch(num):\n",
    "    if num == 0:\n",
    "        return 2\n",
    "    elif num == 2:\n",
    "        return 0\n",
    "    else:\n",
    "        return num\n",
    "\n",
    "ax[1].scatter(x=penguins_X['flipper_length_mm'],\n",
    "          y=penguins_X['culmen_length_mm'],\n",
    "          c=list(map(switch, preds2)))\n",
    "ax[1].set_title(f'Agglomerative Clustering')\n",
    "\n",
    "acc = round(accuracy_score(penguins_num['spec_num'], list(map(switch, preds2))), 3)\n",
    "ax[1].text(x=210, y=35, s=f'Accuracy: {acc}', c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try single `linkage`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg2 = AgglomerativeClustering(n_clusters=3, linkage='single')\n",
    "# Trying the \"nearest point\" single linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2b = agg2.fit_predict(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "scatter = ax[0].scatter(x=penguins_num['flipper_length_mm'],\n",
    "          y=penguins_num['culmen_length_mm'],\n",
    "          c=penguins_num['spec_num'])\n",
    "\n",
    "legend1 = ax[0].legend(*scatter.legend_elements(),\n",
    "                    loc=\"best\", title=\"Classes\")\n",
    "ax[0].add_artist(legend1)\n",
    "ax[0].set_title('Ground Truth')\n",
    "\n",
    "def switch(num):\n",
    "    if num == 0:\n",
    "        return 2\n",
    "    elif num == 2:\n",
    "        return 0\n",
    "    else:\n",
    "        return num\n",
    "\n",
    "ax[1].scatter(x=penguins_X['flipper_length_mm'],\n",
    "          y=penguins_X['culmen_length_mm'],\n",
    "          c=list(map(switch, preds2b)))\n",
    "ax[1].set_title(f'Agglomerative Clustering 2')\n",
    "\n",
    "acc = round(accuracy_score(penguins_num['spec_num'], list(map(switch, preds2b))), 3)\n",
    "ax[1].text(x=210, y=35, s=f'Accuracy: {acc}', c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try complete `linkage`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg3 = AgglomerativeClustering(n_clusters=3, linkage='complete')\n",
    "# Trying the \"farthest point\" complete linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2c = agg3.fit_predict(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "scatter = ax[0].scatter(x=penguins_num['flipper_length_mm'],\n",
    "          y=penguins_num['culmen_length_mm'],\n",
    "          c=penguins_num['spec_num'])\n",
    "\n",
    "legend1 = ax[0].legend(*scatter.legend_elements(),\n",
    "                    loc=\"best\", title=\"Classes\")\n",
    "ax[0].add_artist(legend1)\n",
    "ax[0].set_title('Ground Truth')\n",
    "\n",
    "def switch(num):\n",
    "    if num == 0:\n",
    "        return 2\n",
    "    elif num == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "ax[1].scatter(x=penguins_X['flipper_length_mm'],\n",
    "          y=penguins_X['culmen_length_mm'],\n",
    "          c=list(map(switch, preds2c)))\n",
    "ax[1].set_title(f'Agglomerative Clustering 3')\n",
    "\n",
    "acc = round(accuracy_score(penguins_num['spec_num'], list(map(switch, preds2c))), 3)\n",
    "ax[1].text(x=210, y=35, s=f'Accuracy: {acc}', c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 3: Birch Clustering\n",
    "\n",
    "Birch clustering constructs a kind of dendrogram à la hierarchical clustering, but its performance is often similar to k-means clustering. It is most useful for datasets with many rows but few columns and it can also handle a certain amount of noise in the data. The `threshold` parameter determines how close subclusters need to be before merging. See `sklearn` documentation [here](https://scikit-learn.org/stable/modules/clustering.html#birch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birch = Birch()\n",
    "\n",
    "birch.fit(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds3 = birch.predict(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "scatter = ax[0].scatter(x=penguins_num['flipper_length_mm'],\n",
    "          y=penguins_num['culmen_length_mm'],\n",
    "          c=penguins_num['spec_num'])\n",
    "\n",
    "legend1 = ax[0].legend(*scatter.legend_elements(),\n",
    "                    loc=\"best\", title=\"Classes\")\n",
    "ax[0].add_artist(legend1)\n",
    "ax[0].set_title('Ground Truth')\n",
    "\n",
    "def switch(num):\n",
    "    if num == 0:\n",
    "        return 2\n",
    "    elif num == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "ax[1].scatter(x=penguins_X['flipper_length_mm'],\n",
    "          y=penguins_X['culmen_length_mm'],\n",
    "          c=list(map(switch, preds3)))\n",
    "ax[1].set_title(f'Birch Clustering')\n",
    "\n",
    "acc = round(accuracy_score(penguins_num['spec_num'], list(map(switch, preds3))), 3)\n",
    "ax[1].text(x=210, y=35, s=f'Accuracy: {acc}', c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusting `threshold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birch2 = Birch(threshold=5)\n",
    "\n",
    "birch2.fit(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds3b = birch2.predict(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "scatter = ax[0].scatter(x=penguins_num['flipper_length_mm'],\n",
    "          y=penguins_num['culmen_length_mm'],\n",
    "          c=penguins_num['spec_num'])\n",
    "\n",
    "legend1 = ax[0].legend(*scatter.legend_elements(),\n",
    "                    loc=\"best\", title=\"Classes\")\n",
    "ax[0].add_artist(legend1)\n",
    "ax[0].set_title('Ground Truth')\n",
    "\n",
    "def switch(num):\n",
    "    if num == 1:\n",
    "        return 2\n",
    "    elif num == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return num\n",
    "\n",
    "ax[1].scatter(x=penguins_X['flipper_length_mm'],\n",
    "          y=penguins_X['culmen_length_mm'],\n",
    "          c=list(map(switch, preds3b)))\n",
    "ax[1].set_title(f'Birch Clustering 2')\n",
    "\n",
    "acc = round(accuracy_score(penguins_num['spec_num'], list(map(switch, preds3b))), 3)\n",
    "ax[1].text(x=210, y=35, s=f'Accuracy: {acc}', c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 4: Density-Based Spatial Clustering of Applications with Noise (DBSCAN)\n",
    "\n",
    "DBSCAN clusters points according to *density*. When sufficiently many points are sufficiently close together (the user can modify these), then those points are called a cluster. See `sklearn` documentation [here](https://scikit-learn.org/stable/modules/clustering.html#dbscan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = DBSCAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds4 = dbs.fit_predict(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "scatter = ax[0].scatter(x=penguins_num['flipper_length_mm'],\n",
    "          y=penguins_num['culmen_length_mm'],\n",
    "          c=penguins_num['spec_num'])\n",
    "\n",
    "legend1 = ax[0].legend(*scatter.legend_elements(),\n",
    "                    loc=\"best\", title=\"Classes\")\n",
    "ax[0].add_artist(legend1)\n",
    "ax[0].set_title('Ground Truth')\n",
    "\n",
    "ax[1].scatter(x=penguins_X['flipper_length_mm'],\n",
    "          y=penguins_X['culmen_length_mm'],\n",
    "          c=preds4)\n",
    "ax[1].set_title(f'DBSCAN, {len(np.unique(preds4))} Clusters');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusting `eps`, `min_samples`\n",
    "\n",
    "Let's try increasing `eps` and decreasing `min_samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs2 = DBSCAN(eps=2, min_samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds4b = dbs2.fit_predict(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "scatter = ax[0].scatter(x=penguins_num['flipper_length_mm'],\n",
    "          y=penguins_num['culmen_length_mm'],\n",
    "          c=penguins_num['spec_num'])\n",
    "\n",
    "legend1 = ax[0].legend(*scatter.legend_elements(),\n",
    "                    loc=\"best\", title=\"Classes\")\n",
    "ax[0].add_artist(legend1)\n",
    "ax[0].set_title('Ground Truth')\n",
    "\n",
    "ax[1].scatter(x=penguins_X['flipper_length_mm'],\n",
    "          y=penguins_X['culmen_length_mm'],\n",
    "          c=preds4b)\n",
    "ax[1].set_title(f'DBSCAN2, {len(np.unique(preds4b))} Clusters');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 5: Gaussian Mixture Modeling\n",
    "\n",
    "A Gaussian mixture is what it sounds like: A model that treats the data as belonging to distinct normal distributions. The `sklearn` tool lets us choose the number of groups we're modeling. See `sklearn` documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss = GaussianMixture(n_components=3, random_state=42)\n",
    "\n",
    "gauss.fit(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds5 = gauss.predict(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "scatter = ax[0].scatter(x=penguins_num['flipper_length_mm'],\n",
    "          y=penguins_num['culmen_length_mm'],\n",
    "          c=penguins_num['spec_num'])\n",
    "\n",
    "legend1 = ax[0].legend(*scatter.legend_elements(),\n",
    "                    loc=\"best\", title=\"Classes\")\n",
    "ax[0].add_artist(legend1)\n",
    "ax[0].set_title('Ground Truth')\n",
    "\n",
    "def switch(num):\n",
    "    if num == 1:\n",
    "        return 2\n",
    "    elif num == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return num\n",
    "\n",
    "ax[1].scatter(x=penguins_X['flipper_length_mm'],\n",
    "          y=penguins_X['culmen_length_mm'],\n",
    "          c=list(map(switch, preds5)))\n",
    "ax[1].set_title(f'Gaussian Mixture')\n",
    "\n",
    "acc = round(accuracy_score(penguins_num['spec_num'], list(map(switch, preds5))), 3)\n",
    "ax[1].text(x=210, y=35, s=f'Accuracy: {acc}', c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusting `covariance_type`\n",
    "\n",
    "The covariance matrix is one way of [describing a Gaussian](https://stats.stackexchange.com/questions/326671/different-covariance-types-for-gaussian-mixture-models) distribution. Since our groups have roughly the same shape, we might try the 'tied' type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss2 = GaussianMixture(n_components=3, covariance_type='tied',\n",
    "                        random_state=42)\n",
    "\n",
    "gauss2.fit(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds5b = gauss2.predict(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "scatter = ax[0].scatter(x=penguins_num['flipper_length_mm'],\n",
    "          y=penguins_num['culmen_length_mm'],\n",
    "          c=penguins_num['spec_num'])\n",
    "\n",
    "legend1 = ax[0].legend(*scatter.legend_elements(),\n",
    "                    loc=\"best\", title=\"Classes\")\n",
    "ax[0].add_artist(legend1)\n",
    "ax[0].set_title('Ground Truth')\n",
    "\n",
    "def switch(num):\n",
    "    if num == 1:\n",
    "        return 2\n",
    "    elif num == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return num\n",
    "\n",
    "ax[1].scatter(x=penguins_X['flipper_length_mm'],\n",
    "          y=penguins_X['culmen_length_mm'],\n",
    "          c=list(map(switch, preds5b)))\n",
    "ax[1].set_title(f'Gaussian Mixture 2')\n",
    "\n",
    "acc = round(accuracy_score(penguins_num['spec_num'], list(map(switch, preds5b))), 3)\n",
    "ax[1].text(x=210, y=35, s=f'Accuracy: {acc}', c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 6: Mean Shift\n",
    "\n",
    "The mean shift strategy is in the general family of centroid approaches to clustering that includes $k$-means, but mean shift does not require a number of clusters to be selected in advance. A `bandwidth` parameter can be set that will determine the size of the area to be searched for nearest neighbors. See sklearn documentation [here](https://scikit-learn.org/stable/modules/clustering.html#mean-shift)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = MeanShift()\n",
    "\n",
    "ms.fit(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds6 = ms.predict(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "scatter = ax[0].scatter(x=penguins_num['flipper_length_mm'],\n",
    "          y=penguins_num['culmen_length_mm'],\n",
    "          c=penguins_num['spec_num'])\n",
    "\n",
    "legend1 = ax[0].legend(*scatter.legend_elements(),\n",
    "                    loc=\"best\", title=\"Classes\")\n",
    "ax[0].add_artist(legend1)\n",
    "ax[0].set_title('Ground Truth')\n",
    "\n",
    "ax[1].scatter(x=penguins_X['flipper_length_mm'],\n",
    "          y=penguins_X['culmen_length_mm'],\n",
    "          c=preds6)\n",
    "ax[1].set_title(f'MeanShift, {len(np.unique(preds6))} Clusters');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import estimate_bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_bandwidth(penguins_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusting `bandwidth`\n",
    "\n",
    "The bandwidth estimate above led to only two clusters. Let's see if wee can alter it so as to produce three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms2 = MeanShift(bandwidth=8)\n",
    "\n",
    "ms2.fit(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds6b = ms2.predict(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "scatter = ax[0].scatter(x=penguins_num['flipper_length_mm'],\n",
    "          y=penguins_num['culmen_length_mm'],\n",
    "          c=penguins_num['spec_num'])\n",
    "\n",
    "legend1 = ax[0].legend(*scatter.legend_elements(),\n",
    "                    loc=\"best\", title=\"Classes\")\n",
    "ax[0].add_artist(legend1)\n",
    "ax[0].set_title('Ground Truth')\n",
    "\n",
    "def switch(num):\n",
    "    if num == 1:\n",
    "        return 2\n",
    "    elif num == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return num\n",
    "\n",
    "ax[1].scatter(x=penguins_X['flipper_length_mm'],\n",
    "          y=penguins_X['culmen_length_mm'],\n",
    "          c=preds6b)\n",
    "ax[1].set_title(f'MeanShift, {len(np.unique(preds6b))} Clusters')\n",
    "\n",
    "acc = round(accuracy_score(penguins_num['spec_num'], list(map(switch, preds6b))), 3)\n",
    "ax[1].text(x=210, y=35, s=f'Accuracy: {acc}', c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 7: $k$-Means\n",
    "\n",
    "The $k$-means strategy is one of the most popular clustering algorithms. Centroids are first chosen randomly. Then points are assigned clusters based on the nearest centroid. Then centroid positions are updated and the process repeats. See `sklearn` documentation [here](https://scikit-learn.org/stable/modules/clustering.html#k-means)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "\n",
    "kmeans.fit(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds7 = kmeans.predict(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "scatter = ax[0].scatter(x=penguins_num['flipper_length_mm'],\n",
    "          y=penguins_num['culmen_length_mm'],\n",
    "          c=penguins_num['spec_num'])\n",
    "\n",
    "legend1 = ax[0].legend(*scatter.legend_elements(),\n",
    "                    loc=\"best\", title=\"Classes\")\n",
    "ax[0].add_artist(legend1)\n",
    "ax[0].set_title('Ground Truth')\n",
    "\n",
    "def switch(num):\n",
    "    if num == 1:\n",
    "        return 2\n",
    "    elif num == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return num\n",
    "\n",
    "ax[1].scatter(x=penguins_X['flipper_length_mm'],\n",
    "          y=penguins_X['culmen_length_mm'],\n",
    "          c=list(map(switch, preds7)))\n",
    "ax[1].set_title(f'k-Means Clustering')\n",
    "\n",
    "acc = round(accuracy_score(penguins_num['spec_num'],\n",
    "                           list(map(switch, preds7))), 3)\n",
    "ax[1].text(x=210, y=35, s=f'Accuracy: {acc}', c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 8: OPTICS\n",
    "\n",
    "OPTICS is in the same family as DBSCAN, but it uses an epsilon range rather than a single value. Data points have reachability and ordering scores. See `sklearn` documentation [here](https://scikit-learn.org/stable/modules/clustering.html#optics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optics = OPTICS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds8 = optics.fit_predict(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "scatter = ax[0].scatter(x=penguins_num['flipper_length_mm'],\n",
    "          y=penguins_num['culmen_length_mm'],\n",
    "          c=penguins_num['spec_num'])\n",
    "\n",
    "legend1 = ax[0].legend(*scatter.legend_elements(),\n",
    "                    loc=\"best\", title=\"Classes\")\n",
    "ax[0].add_artist(legend1)\n",
    "ax[0].set_title('Ground Truth')\n",
    "\n",
    "ax[1].scatter(x=penguins_X['flipper_length_mm'],\n",
    "          y=penguins_X['culmen_length_mm'],\n",
    "          c=preds8)\n",
    "ax[1].set_title(f'OPTICS, {len(np.unique(preds8))} Clusters');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusting `min_cluster_size`\n",
    "\n",
    "This defaults to 5. Since we got so many clusters with that setting, let's try a larger number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optics2 = OPTICS(min_cluster_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds8b = optics2.fit_predict(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "scatter = ax[0].scatter(x=penguins_num['flipper_length_mm'],\n",
    "          y=penguins_num['culmen_length_mm'],\n",
    "          c=penguins_num['spec_num'])\n",
    "\n",
    "legend1 = ax[0].legend(*scatter.legend_elements(),\n",
    "                    loc=\"best\", title=\"Classes\")\n",
    "ax[0].add_artist(legend1)\n",
    "ax[0].set_title('Ground Truth')\n",
    "\n",
    "def switch(num):\n",
    "    if num == 0:\n",
    "        return 1\n",
    "    elif num == 1:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "ax[1].scatter(x=penguins_X['flipper_length_mm'],\n",
    "          y=penguins_X['culmen_length_mm'],\n",
    "          c=preds8b)\n",
    "ax[1].set_title(f'OPTICS 2, {len(np.unique(preds8b))} Clusters')\n",
    "\n",
    "acc = round(accuracy_score(penguins_num['spec_num'],\n",
    "                           list(map(switch, preds8b))), 3)\n",
    "ax[1].text(x=210, y=35, s=f'Accuracy: {acc}', c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 9: Spectral\n",
    "\n",
    "Spectral clustering transforms the problem to a lower-dimensional one and then clusters eigenvector components in the lower-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = SpectralClustering(n_clusters=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds9 = spec.fit_predict(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "scatter = ax[0].scatter(x=penguins_num['flipper_length_mm'],\n",
    "          y=penguins_num['culmen_length_mm'],\n",
    "          c=penguins_num['spec_num'])\n",
    "\n",
    "legend1 = ax[0].legend(*scatter.legend_elements(),\n",
    "                    loc=\"best\", title=\"Classes\")\n",
    "ax[0].add_artist(legend1)\n",
    "ax[0].set_title('Ground Truth')\n",
    "\n",
    "def switch(num):\n",
    "    if num == 0:\n",
    "        return 2\n",
    "    elif num == 2:\n",
    "        return 0\n",
    "    else:\n",
    "        return num\n",
    "\n",
    "ax[1].scatter(x=penguins_X['flipper_length_mm'],\n",
    "          y=penguins_X['culmen_length_mm'],\n",
    "          c=preds9)\n",
    "ax[1].set_title(f'Spectral Clustering')\n",
    "\n",
    "acc = round(accuracy_score(penguins_num['spec_num'],\n",
    "                           list(map(switch, preds9))), 3)\n",
    "ax[1].text(x=210, y=35, s=f'Accuracy: {acc}', c='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec2 = SpectralClustering(n_clusters=3, affinity='nearest_neighbors',\n",
    "                         n_neighbors=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds9b = spec2.fit_predict(penguins_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mpl.pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "scatter = ax[0].scatter(x=penguins_num['flipper_length_mm'],\n",
    "          y=penguins_num['culmen_length_mm'],\n",
    "          c=penguins_num['spec_num'])\n",
    "\n",
    "legend1 = ax[0].legend(*scatter.legend_elements(),\n",
    "                    loc=\"best\", title=\"Classes\")\n",
    "ax[0].add_artist(legend1)\n",
    "ax[0].set_title('Ground Truth')\n",
    "\n",
    "def switch(num):\n",
    "    if num == 0:\n",
    "        return 2\n",
    "    elif num == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "ax[1].scatter(x=penguins_X['flipper_length_mm'],\n",
    "          y=penguins_X['culmen_length_mm'],\n",
    "          c=preds9b)\n",
    "ax[1].set_title(f'Spectral Clustering 2')\n",
    "\n",
    "acc = round(accuracy_score(penguins_num['spec_num'],\n",
    "                           list(map(switch, preds9b))), 3)\n",
    "ax[1].text(x=210, y=35, s=f'Accuracy: {acc}', c='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
