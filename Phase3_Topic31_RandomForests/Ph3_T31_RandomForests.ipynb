{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-family:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Ensemble Learning: Bagging and Random Forests\n",
    "              \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Data Science Cohort Live NYC Feb 2022\n",
    "<p>Phase 3: Topic 31</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"Images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,\\\n",
    "cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier,\\\n",
    "ExtraTreesClassifier, VotingClassifier, StackingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Motivation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Kim-Jong-un after using decision tree: launch nukes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/kimjongun.jpg\" width = 700 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Maybe better to make this a more democratic process with more perspectives on the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Other decision makers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<table><tr><td><img src=\"Images/mother_teresa.webp\" width=\"250\"/><br><center>Mother Theresa</center></td><td><img src=\"Images/sakharov.jpg\" width=\"200\"/><br><center>Andrei Sakharov</center></td><td><img src=\"Images/cat_press_button.gif\" width=\"300\"/><br><center>Nice kitty.</center></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This thinking applicable to all models:\n",
    "- particularly useful in the context of Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Deficiencies of Decision Trees:\n",
    "- that ensemble learning can address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Reminder of decision trees: \n",
    "- recursively make splits based on entropy or impurity\n",
    "- split on feature best increasing information gain\n",
    "- Keep splitting until leaf pure OR max depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/dec_tree_partitioning.jpg\" width = 800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Tendency to overfit at large max depth.\n",
    "- High enough depth: will fit to training set perfectly.\n",
    "\n",
    "<img src = \"Images/dectree_perfectfit.png\" />\n",
    "<center> A perfect fit to the training set. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/decisiontree_classification_overfitting.png\"  />\n",
    "<center> Some more decision tree overfitting </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Too much **variance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To avoid: reduce decision tree depth to limit variance.\n",
    "    \n",
    "But with decision tree, will easily end up underfitting.\n",
    "\n",
    "- Can increase depth again to get better:\n",
    "    - But very likely to learn a boundary that overfits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/dectree_underfitting.png\" width = 400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bias-variance problem is severe with Decision Tree models:\n",
    "- Very sensitive to tree depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A very nice visualization of this sensitivity on the regression task:\n",
    "<img src = \"Images/decision_tree_regression.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Decision trees not-robust**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Criterion is harsh: choose *single* feature that wins and split on that.\n",
    "- But many features may be important in a region and should be factored in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src = \"Images/tree_features.png\" />\n",
    "Both Culmen length and depth matter here. But split for each region considers only one or the other.\n",
    "\n",
    "- Doesn't reflect the way features are related to each other and collectively impact the target.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Can we figure out a way in a split for a given subregion to factor in different features?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Depending on goal could be nice if modeling target-feature function:\n",
    "- without feature engineering.\n",
    "- without distributional assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Another issue:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Recursion: after split on \"best\" feature, different subsets never talk to each other again.\n",
    "- But maybe other branches/regions: info influencing split/class assignment in given subregion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/dec_tree_partitioning.jpg\" width =800/>\n",
    "<center>Choosing next split in green region: black or green?</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Perhaps sampling/factoring in different regions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Increasing depth and number of splits:\n",
    "- Very quickly: small number of points in given sub-region\n",
    "- Feature decision very sensitive to points in specific region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points.png\" width = 200 />\n",
    "<center> Plausible small subregion with few points </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Two possible choices (equivalent in terms of impurity):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points_splt1.png\" width = 200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points_splt2.png\" width = 200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Decision boundary instability: \n",
    "- small changes/fluctuations in data lead to very different decision surface locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points_splt1_inst.png\" width =400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points_splt2_inst.png\" width =400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How to get around this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Don't want to rely too heavily on specific data points and their location:\n",
    "- Maybe introducing randomness in data point sampling in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Why am I using decision trees at all then?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### But decision trees are blindingly fast.\n",
    "- Recursion on binary trees\n",
    "- Greedy criterion:\n",
    "    - always split on best feature at local node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Want to keep this speed and still use trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But also want to:\n",
    "- Sample other features when making splits\n",
    "- Sample other regions in feature-space when making decisions on class assignments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Learn from classifiers training on different realizations of the dataset:\n",
    "    - a set of given points has different weight/importance in each realization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Way to create realization of dataset with different weights for data: \n",
    "- **Bagging (boostrap aggregation)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/sample_bagging_only.png\" width = 800/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src = \"Images/sample_bagging_only.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The boostrap:\n",
    "\n",
    "- N samples in training set.\n",
    "- Randomly resample training set **with replacement** N times.\n",
    "- Resampled set also has N samples.\n",
    "\n",
    "A given point now has different weight/importance in each realization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "More explicitly: see training point reweighting under bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. ,  1. ],\n",
       "       [ 3.1,  0. ],\n",
       "       [-2.5,  1. ],\n",
       "       [ 1. ,  0. ],\n",
       "       [-4. ,  1. ],\n",
       "       [ 0.5,  0. ]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (feature, label) pairs\n",
    "train = np.array([(-1,1), (3.1, 0) , (-2.5, 1),\n",
    "         (1, 0), (-4, 1), (.5, 0)])\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0. ],\n",
       "       [-4. ,  1. ],\n",
       "       [ 0.5,  0. ],\n",
       "       [ 1. ,  0. ],\n",
       "       [-1. ,  1. ],\n",
       "       [ 1. ,  0. ]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.random import choice\n",
    "idx_resampled =choice(range(len(train)), \n",
    "                      size = len(train),\n",
    "                       replace = True)\n",
    "train[idx_resampled]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Now use ensemble of trained models\n",
    "- Aggregate to make prediction on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/bagging_classifier.png\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the context of regression:\n",
    "- aggregation function is average of regressor trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/bagging_regressor.png\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The concept of bagging of estimators is **NOT** limited to trees:\n",
    "- can use any classifier or regressor and perform bagging procedures.\n",
    "- but mainly useful for local models like DecisionTree or KNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To implement bagging classifier in sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# if doing classification\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# if doing regression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll do classification:\n",
    "- Predict diabetes via health stats\n",
    "- Pima Indian diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diab_df = pd.read_csv('Data/diabetes.csv')\n",
    "diab_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "diab_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diab_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separate features and target\n",
    "- Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "X = diab_df.drop(columns = ['Outcome'])\n",
    "y = diab_df['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now develop our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Define the bagging classifier and put it into a pipeline. \n",
    "\n",
    "Then integrate into a grid search tuning on tree depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bag_class_decision = BaggingClassifier(base_estimator = DecisionTreeClassifier(), n_estimators = 150)\n",
    "bag_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                      ('model',\n",
    "                       bag_class_decision)])\n",
    "params = {'model__base_estimator__max_depth': np.arange(4,28,4)}\n",
    "cv = GridSearchCV(estimator = bag_pipe, param_grid = params, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cv.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Get best model and its balanced accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__base_estimator__max_depth': 16}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = cv.best_estimator_\n",
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.785237815619495"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__base_estimator__max_depth</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.772930</td>\n",
       "      <td>0.041764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.777592</td>\n",
       "      <td>0.029653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0.777569</td>\n",
       "      <td>0.028975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.785238</td>\n",
       "      <td>0.028964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0.769912</td>\n",
       "      <td>0.034087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>0.782231</td>\n",
       "      <td>0.015462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_model__base_estimator__max_depth  mean_test_score  std_test_score\n",
       "0                                      4         0.772930        0.041764\n",
       "1                                      8         0.777592        0.029653\n",
       "2                                     12         0.777569        0.028975\n",
       "3                                     16         0.785238        0.028964\n",
       "4                                     20         0.769912        0.034087\n",
       "5                                     24         0.782231        0.015462"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv.cv_results_)[['param_model__base_estimator__max_depth', 'mean_test_score', 'std_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Fit the best model. Get predictions and report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "best_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75        76\n",
      "           1       0.53      0.57      0.55        40\n",
      "\n",
      "    accuracy                           0.68       116\n",
      "   macro avg       0.65      0.66      0.65       116\n",
      "weighted avg       0.69      0.68      0.68       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Is bagging better than baseline decision tree over the same range of tree depths?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "simpletree_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                      ('model',\n",
    "                       DecisionTreeClassifier())]) \n",
    "\n",
    "params = {'model__max_depth': np.arange(4,28,4)}\n",
    "\n",
    "cvtree = GridSearchCV(estimator = simpletree_pipe, param_grid = params, cv = 5)\n",
    "\n",
    "cvtree.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__max_depth': 4}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_simplemodel = cvtree.best_estimator_\n",
    "cvtree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7607046388725778"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvtree.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.66      0.74        76\n",
      "           1       0.54      0.75      0.63        40\n",
      "\n",
      "    accuracy                           0.69       116\n",
      "   macro avg       0.68      0.70      0.68       116\n",
      "weighted avg       0.73      0.69      0.70       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_simplemodel.fit(X_train, y_train)\n",
    "y_pred_simple = best_simplemodel.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Baggiing a bit better on the precision/recall for all classes -- especially positive class. \n",
    "- In many cases improvements on bagging alone will not be so significant.\n",
    "- Sample bagging alone usually not enough to capture feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Reason: \n",
    "- boostrapped samples are still highly correlated with each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Final ingredient (first set of strategies)\n",
    "\n",
    "- Effectively factor in other features when making splits\n",
    "- Sample other regions in feature-space when making decisions on class assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Can effectively do this by considering only a random subset of features to split on at each node\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Result: each tree may partition feature space in appreciably different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src = \"Images/rf_splitting.png\"  width = 600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Overall effect of this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/indtree.gif\"  width = 600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Each decision tree can learn different important features to make splits on throughout feature space.\n",
    "- Each tree can assign a given feature region to different classes based on its splits factoring in different features.\n",
    "\n",
    "Individual trees making errors but **different** errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src = \"Images/rfplot.gif\"  width = 600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Aggregating smooths large fluctuations of class assignments from individual trees out.\n",
    "- Due to feature subset sampling: can learn more complex boundaries: smoothens these.\n",
    "- Can also get probability of class assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's try out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                      ('model',\n",
    "                       RandomForestClassifier(n_estimators = 100))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rf_pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_rf_pred = rf_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78        76\n",
      "           1       0.58      0.55      0.56        40\n",
      "\n",
      "    accuracy                           0.71       116\n",
      "   macro avg       0.67      0.67      0.67       116\n",
      "weighted avg       0.70      0.71      0.71       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Better than bagging and base Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Should tune model: understand relevant hyperparameters\n",
    "- understand parameters of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- n_estimators: number of trees in forest (very important):\n",
    "    - optimal will depend on dataset size. But 50-250 is good starting tuning range.\n",
    "- max_features: number of features to randomly sample at each node for evaluating split criterion.\n",
    "    - good starting value (also default) is $\\sqrt{M}$ where $M$ is number of features. (theoretical justification for this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- max_depth: tree depth\n",
    "    - due to randomizing and averaging: random forest not as sensitive to this as DecisionTree.\n",
    "    - default is None. Trains tree to leaf purity. Typically don't touch this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- min_sample_leaf: minimum number of samples required to be at a leaf node.\n",
    "    - Default is 1 but having larger numbers can mean averaging effect from leaf\n",
    "    - Higher values can have a regularizing effect.\n",
    "    - Typically tune from 1-100 (depends on size of data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For min sample leaf criterion: cuts out different portions of tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/min_sample_leaf.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Can also change objective functions:\n",
    "- Gini\n",
    "- entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Grid Search CV on our random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('model', RandomForestClassifier())]),\n",
       "             param_grid={'model__min_samples_leaf': [1, 3, 5, 7],\n",
       "                         'model__n_estimators': [50, 100, 200, 500]})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {'model__n_estimators': [50, 100, 200, 500] ,\n",
    "             'model__min_samples_leaf': [1,3,5,7]}\n",
    "rf_cv = GridSearchCV(estimator = rf_pipe, param_grid = rf_params, cv = 5)\n",
    "rf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7837345860246623"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__min_samples_leaf': 1, 'model__n_estimators': 200}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('model', RandomForestClassifier(n_estimators=200))])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_model = rf_cv.best_estimator_\n",
    "best_rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('model', RandomForestClassifier(n_estimators=200))])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.83        76\n",
      "           1       0.71      0.50      0.59        40\n",
      "\n",
      "    accuracy                           0.76       116\n",
      "   macro avg       0.74      0.70      0.71       116\n",
      "weighted avg       0.75      0.76      0.75       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_rfcv_pred = best_rf_model.predict(X_test)\n",
    "print(classification_report(y_test,y_rfcv_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "OK this is pretty decent. There is also another nice thing about random forests:\n",
    "\n",
    "Can see which features are most important in prediction:\n",
    "\n",
    "- .feature_importances_ attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "feat_imp = best_rf_model['model'].feature_importances_\n",
    "\n",
    "feat_imp_series = pd.Series(feat_imp, \n",
    "          index = X.columns).sort_values(\n",
    "    ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Glucose                     0.249453\n",
       "BMI                         0.167054\n",
       "Age                         0.135086\n",
       "DiabetesPedigreeFunction    0.124160\n",
       "BloodPressure               0.089423\n",
       "Pregnancies                 0.089225\n",
       "Insulin                     0.073816\n",
       "SkinThickness               0.071781\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_imp_series.plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Evaluates feature importance:\n",
    "- Determining for each tree how many times feature was used for splitting.\n",
    "- Counts up occurences across entire forest and weights features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Extremely Randomized Trees (Extra Trees)\n",
    "- Sometimes our variance problems are extreme.\n",
    "- Random forest taking way too long with too many estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Might want even one more randomization. \n",
    "- Instead of always choosing the *optimal* split at node:\n",
    "    - randomly sample feature space inside node. \n",
    "    - split on best information gain from random sample.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now **three** levels of randomization: \n",
    "- sampling of data\n",
    "- sampling of features\n",
    "- random selection of branching paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Compare typical effects:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src = \"Images/extraatrees_forest_iris.png\" width = 600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Extra randomness makes ExtraTrees a softer classifier.\n",
    "- Very good for variance issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's import it and do our magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate an ExtraTreesClassifier\n",
    "\n",
    "etc = ExtraTreesClassifier(max_features='sqrt',\n",
    "                         max_samples=0.5,\n",
    "                         bootstrap=True,\n",
    "                         random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=True, max_features='sqrt', max_samples=0.5,\n",
       "                     random_state=1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit it\n",
    "\n",
    "etc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74045802, 0.74045802, 0.73846154, 0.79230769, 0.79230769])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validation\n",
    "\n",
    "scores = cross_val_score(estimator=etc, X=X_train,\n",
    "               y=y_train, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7404580152671756"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7758620689655172"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score on test\n",
    "\n",
    "etc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83        76\n",
      "           1       0.69      0.62      0.66        40\n",
      "\n",
      "    accuracy                           0.78       116\n",
      "   macro avg       0.75      0.74      0.75       116\n",
      "weighted avg       0.77      0.78      0.77       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_etc_pred = etc.predict(X_test)\n",
    "print(classification_report(y_test, y_etc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Sometimes** the extra randomization can do even better.\n",
    "- When suffering from variance issues.\n",
    "- Also ExtraTrees is very very fast:\n",
    "    - doesn't spend too much time on finding optimal splits."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
