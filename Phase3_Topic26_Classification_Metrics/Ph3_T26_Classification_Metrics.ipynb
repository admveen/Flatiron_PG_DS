{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-family:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Classification Metrics\n",
    "              \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Data Science Cohort Live NYC Feb 2022\n",
    "<p>Phase 3: Topic 26</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"Images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Many classification metrics for evaluating model validation/test set performance:\n",
    "\n",
    "- Changes which model you will pick during hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Choice of evaluation metric:\n",
    "- Major impact on how well model serves its intended goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Scenario: Identifying Fraudulent Credit Card Transactions\n",
    "<center><img src = \"Images/credit_card.png\" width = 400/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "credit_data = pd.read_csv('data/credit_fraud_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    10000 non-null  float64\n",
      " 1   V1      10000 non-null  float64\n",
      " 2   V2      10000 non-null  float64\n",
      " 3   V3      10000 non-null  float64\n",
      " 4   V4      10000 non-null  float64\n",
      " 5   V5      10000 non-null  float64\n",
      " 6   V6      10000 non-null  float64\n",
      " 7   V7      10000 non-null  float64\n",
      " 8   V8      10000 non-null  float64\n",
      " 9   V9      10000 non-null  float64\n",
      " 10  V10     10000 non-null  float64\n",
      " 11  V11     10000 non-null  float64\n",
      " 12  V12     10000 non-null  float64\n",
      " 13  V13     10000 non-null  float64\n",
      " 14  V14     10000 non-null  float64\n",
      " 15  V15     10000 non-null  float64\n",
      " 16  V16     10000 non-null  float64\n",
      " 17  V17     10000 non-null  float64\n",
      " 18  V18     10000 non-null  float64\n",
      " 19  V19     10000 non-null  float64\n",
      " 20  V20     10000 non-null  float64\n",
      " 21  V21     10000 non-null  float64\n",
      " 22  V22     10000 non-null  float64\n",
      " 23  V23     10000 non-null  float64\n",
      " 24  V24     10000 non-null  float64\n",
      " 25  V25     10000 non-null  float64\n",
      " 26  V26     10000 non-null  float64\n",
      " 27  V27     10000 non-null  float64\n",
      " 28  V28     10000 non-null  float64\n",
      " 29  Amount  10000 non-null  float64\n",
      " 30  Class   10000 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "credit_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The dataset contains a bunch of features:\n",
    "- The transaction amount\n",
    "- The relative time of the transaction\n",
    "- V1-V28 are relevant features: product of feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Fraud transaction algorithms:\n",
    "- Typically huge number of features \n",
    "- Can create snall combination of features that encompass most variation in the full feature set:\n",
    "    - Principal component analysis (PCA)\n",
    "    - V1-V28 are these combination features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Target 'Class':\n",
    "- 1 if the transaction was fraudulent\n",
    "- 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9962\n",
       "1      38\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What have we just learned about our target in our dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Run a logistic regression on the credit card fraud data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate data into feature and target DataFrames\n",
    "X = credit_data.drop('Class', axis = 1)\n",
    "y = credit_data['Class']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25,\n",
    "                                                   random_state=1)\n",
    "# Scale the data for modeling\n",
    "cred_scaler = StandardScaler()\n",
    "cred_scaler.fit(X_train)\n",
    "X_train_sc = cred_scaler.transform(X_train)\n",
    "X_test_sc = cred_scaler.transform(X_test)\n",
    "\n",
    "# Train a logistic regresssion model with the train data\n",
    "cred_model = LogisticRegression(random_state=42)\n",
    "cred_model.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remember:\n",
    "- .score(X,y) gets the accuracy of our classification model on predicting y given X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cred_model.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We got 99.88% accuracy! \n",
    "- Our model is good. Right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Think again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Accuracy** = $\\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "\n",
    "- Fraction of correct classifications.\n",
    "- What the `.score()` method calculates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**Class 1 (Fraud) = Our positive class**\n",
    "\n",
    "- TP: True positive\n",
    "- FP: False positive\n",
    "- TN: True negative\n",
    "- FN: False negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Easy way to unpack the TP, TN, FP, FN is using the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import plot_confusion_matrix #nice function to visualize confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2493,    0],\n",
       "       [   3,    4]], dtype=int64)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get predictions\n",
    "y_pred = cred_model.predict(X_test_sc) \n",
    "# calculate confusion matrix\n",
    "cfmat = confusion_matrix(y_test, y_pred) \n",
    "\n",
    "cfmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cred_model, \n",
    "                      X_test_sc, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2493 0 3 4\n",
      "[[2493    0]\n",
      " [   3    4]]\n"
     ]
    }
   ],
   "source": [
    "tn, fn, fp, tp = cfmat.flatten()\n",
    "print(tn,fn,fp,tp)\n",
    "\n",
    "print(cfmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cred_model, \n",
    "                      X_test_sc, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9988\n"
     ]
    }
   ],
   "source": [
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cred_model.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "My accuracy is great. But is model doing well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "True positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true positives\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false positives\n",
    "fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Model not doing well on fraud detection.\n",
    "\n",
    "But the accuracy is great. What happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Accuracy is not a great metric when:\n",
    "- There's a class imbalance\n",
    "- When we care about the positive detections rate for *each* given class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### A better metric (for this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Precision** = $\\frac{TP}{TP + FP}$\n",
    "\n",
    "In this case: \n",
    "- Of the model's prediction of 'fraudulent', how many of those predictions were correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec = tp/(tp+fp)\n",
    "prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the given task of detecting credit card fraud:\n",
    "    \n",
    "Is precision something that the credit card company cares a lot about?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Another metric that could be important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Recall** = **Sensitivity** = $\\frac{TP}{TP + FN}$\n",
    "\n",
    "Of the actual fraudulent transactions in our data, how many did our model predict as fraudulent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "rec = tp / (tp + fn)\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In this task, is recall an important metric? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### A metric balancing both recall and precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An $F$-score is a combination of precision and recall, which can be useful when both are important. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The $F_1$ score is an equal balance of the two using a [harmonic mean](https://en.wikipedia.org/wiki/Harmonic_mean).\n",
    "\n",
    "$$F_1 = 2 \\frac{Precision \\cdot Recall}{Precision + Recall} = \\frac{2TP}{2TP + FP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function f1_score at 0x0000020445F4D430>\n"
     ]
    }
   ],
   "source": [
    "f1_sc = 2*prec*rec / (prec + rec)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Which of these metrics do you think a credit card company would care most about when trying to flag fraudulent transactions to deny?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `classification_report()`\n",
    "\n",
    "- Summary of the various metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "cell_style": "center",
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2493\n",
      "           1       1.00      0.57      0.73         7\n",
      "\n",
      "    accuracy                           1.00      2500\n",
      "   macro avg       1.00      0.79      0.86      2500\n",
      "weighted avg       1.00      1.00      1.00      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Get precision/recall/f1-score for each class.\n",
    "- Also prints out class-averaged precision/recall/f-score.\n",
    "- Support: number of instances of each class in test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Another example: Breast Cancer Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Load the data and train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "cell_style": "split",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "cancer_data_dict = load_breast_cancer()\n",
    "X_cancer = cancer_data_dict['data']\n",
    "cancer_feature_names = cancer_data_dict[\n",
    "    'feature_names']\n",
    "\n",
    "cancer_features = pd.DataFrame(X_cancer, \n",
    "                               columns = cancer_feature_names)\n",
    "cancer_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/fractal_mammogram.png\" width = 600 /></center>\n",
    "<center>Feature engineering mammogram.</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cancer = cancer_data_dict['target']\n",
    "cancer_data_dict['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    " - 0 = malignant\n",
    " - 1 = Benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "cell_style": "center",
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "X_train_bc, X_test_bc, y_train_bc, y_test_bc = train_test_split(cancer_features, y_cancer,\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Standard scale and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=42)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the data\n",
    "bc_scaler = StandardScaler()\n",
    "bc_scaler.fit(X_train_bc)\n",
    "X_train_sc = bc_scaler.transform(X_train_bc)\n",
    "X_test_sc = bc_scaler.transform(X_test_bc)\n",
    "\n",
    "# Run the model\n",
    "bc_model = LogisticRegression(solver='lbfgs', max_iter=10000,\n",
    "                           random_state=42)\n",
    "bc_model.fit(X_train_sc, y_train_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = bc_model.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Calculate the following for this model:\n",
    "- Use scikit-learn's functions for this\n",
    "\n",
    "- Confusion Matrix\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# confusion matrix?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# accuracy, precision, recall, and f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Which of these metrics matter for this breast cancer detection problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Which metric to tune model hyperparameters with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Accuracy: misleading under class imbalance\n",
    "    - Sometimes just fine.\n",
    "- Precision: when false positives are much worse than false negatives\n",
    "    - DNA crime-scene forensics.\n",
    "- Recall: when false negatives are a lot worse \n",
    "    - X-ray imaging for cancer prediction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "**Multiclass classification**: more than two possible values for the target. An example:\n",
    "\n",
    "- Classifying iris sub-species based on petal/sepal characteristics.\n",
    "\n",
    "<center><img src = \"Images/iris-dataset.png\" width = 500 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Same metrics/methods to evaluate our models:\n",
    "- Confusion matrices: number of rows/columns equal to the number of classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Metrics (precision/recall):\n",
    "    - choose one class to be the \"positive\" class.\n",
    "    - rest are assigned to the \"negative\" class. \n",
    "    - compute precision/recall for given \"positive\" class.\n",
    "\n",
    "Repeat for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = load_iris()\n",
    "X = data_dict['data']\n",
    "features = pd.DataFrame(X, columns = data_dict['feature_names'])\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data_dict['target']\n",
    "data_dict['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 0 = setosa\n",
    "- 1 = versicolor\n",
    "- 2 = virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# train-test split \n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(features, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Scale and transform\n",
    "iris_scaler = StandardScaler()\n",
    "X_train_iris_sc = iris_scaler.fit_transform(X_train_iris)\n",
    "X_test_iris_sc = iris_scaler.transform(X_test_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# fit model and get predictions\n",
    "iris_model = LogisticRegression(max_iter = 10000)\n",
    "iris_model.fit(X_train_iris_sc, y_train_iris)\n",
    "y_pred_iris = iris_model.predict(X_test_iris_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "cell_style": "split",
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x20447637790>"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(iris_model, X_test_iris_sc, \n",
    "                      y_test_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our confusion matrix for the multiclass iris problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "cell_style": "center",
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      0.95      0.97        20\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_iris, y_test_iris))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some issues with assessing the quality of a model solely on these metrics:\n",
    "- Need to think a little bit more carefully about probabilities and classification thresholds\n",
    "- The reciever operation curve (up next)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
